{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "## Question 1: \n",
    "\n",
    "### Apply user-based collaborative filtering to the course topics dataset. All recomendations will be 1. Explain why this is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intro</th>\n",
       "      <th>DataMining</th>\n",
       "      <th>Survey</th>\n",
       "      <th>Cat Data</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>DOE</th>\n",
       "      <th>SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Intro  DataMining  Survey  Cat Data  Regression  Forecast  DOE  SW\n",
       "0        1           1       0         0           0         0    0   0\n",
       "1        0           0       1         0           0         0    0   0\n",
       "2        0           1       0         1           1         0    0   1\n",
       "3        1           0       0         0           0         0    0   0\n",
       "4        1           1       0         0           0         0    0   0\n",
       "..     ...         ...     ...       ...         ...       ...  ...  ..\n",
       "360      0           0       0         1           0         0    0   0\n",
       "361      0           1       0         1           0         0    0   1\n",
       "362      0           0       0         0           0         0    0   1\n",
       "363      0           0       0         1           0         0    0   0\n",
       "364      0           0       0         0           1         0    0   0\n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"Coursetopics.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intro         0\n",
       "DataMining    0\n",
       "Survey        0\n",
       "Cat Data      0\n",
       "Regression    0\n",
       "Forecast      0\n",
       "DOE           0\n",
       "SW            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Regression, DOE)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>2.073864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Regression, DOE, DataMining)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Survey, DOE, Intro)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Survey, Regression, Forecast)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Survey, Regression, SW)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Survey, SW, Forecast)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Regression, DOE, Cat Data)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Regression, SW, DOE)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Survey, DOE, DataMining)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Survey, Regression, Forecast)</td>\n",
       "      <td>(DataMining)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Regression, DOE, DataMining)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Forecast, DOE, DataMining)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Survey, DOE, Forecast)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Survey, SW, Forecast)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Survey, Regression, SW)</td>\n",
       "      <td>(DOE)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Forecast, Intro, Cat Data, DataMining)</td>\n",
       "      <td>(Survey)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Survey, Cat Data, Forecast, DataMining)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Survey, DOE, Intro, DataMining)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Survey, Regression, Intro, DataMining)</td>\n",
       "      <td>(Forecast)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Survey, Regression, Forecast, DataMining)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(Survey, Regression, Forecast, Intro)</td>\n",
       "      <td>(DataMining)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Survey, Regression, Forecast)</td>\n",
       "      <td>(Intro, DataMining)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Regression, DOE, Intro, DataMining)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(Regression, DOE, Cat Data, DataMining)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Regression, DOE, DataMining)</td>\n",
       "      <td>(Cat Data, Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(SW, Intro, Cat Data, DataMining)</td>\n",
       "      <td>(Regression)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(Survey, Regression, Cat Data, Intro)</td>\n",
       "      <td>(DOE)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(Survey, Regression, DOE, Cat Data)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(Survey, DOE, Forecast, Intro)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(Forecast, DOE, Cat Data, Intro)</td>\n",
       "      <td>(Survey)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(Survey, SW, Forecast, Intro)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(Forecast, SW, Cat Data, Intro)</td>\n",
       "      <td>(Survey)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(Survey, SW, Cat Data, Forecast)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(Survey, SW, Forecast)</td>\n",
       "      <td>(Cat Data, Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(Survey, Regression, SW, Intro)</td>\n",
       "      <td>(DOE)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(Survey, Regression, SW, DOE)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(Survey, Regression, SW)</td>\n",
       "      <td>(DOE, Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(Regression, SW, Cat Data, DOE)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.534722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   antecedents          consequents  \\\n",
       "0                            (Regression, DOE)              (Intro)   \n",
       "1                (Regression, DOE, DataMining)              (Intro)   \n",
       "2                         (Survey, DOE, Intro)           (Cat Data)   \n",
       "3               (Survey, Regression, Forecast)              (Intro)   \n",
       "4                     (Survey, Regression, SW)              (Intro)   \n",
       "5                       (Survey, SW, Forecast)              (Intro)   \n",
       "6                  (Regression, DOE, Cat Data)              (Intro)   \n",
       "7                        (Regression, SW, DOE)              (Intro)   \n",
       "8                    (Survey, DOE, DataMining)           (Cat Data)   \n",
       "9               (Survey, Regression, Forecast)         (DataMining)   \n",
       "10               (Regression, DOE, DataMining)           (Cat Data)   \n",
       "11                 (Forecast, DOE, DataMining)           (Cat Data)   \n",
       "12                     (Survey, DOE, Forecast)           (Cat Data)   \n",
       "13                      (Survey, SW, Forecast)           (Cat Data)   \n",
       "14                    (Survey, Regression, SW)                (DOE)   \n",
       "15     (Forecast, Intro, Cat Data, DataMining)             (Survey)   \n",
       "16    (Survey, Cat Data, Forecast, DataMining)              (Intro)   \n",
       "17            (Survey, DOE, Intro, DataMining)           (Cat Data)   \n",
       "18     (Survey, Regression, Intro, DataMining)           (Forecast)   \n",
       "19  (Survey, Regression, Forecast, DataMining)              (Intro)   \n",
       "20       (Survey, Regression, Forecast, Intro)         (DataMining)   \n",
       "21              (Survey, Regression, Forecast)  (Intro, DataMining)   \n",
       "22        (Regression, DOE, Intro, DataMining)           (Cat Data)   \n",
       "23     (Regression, DOE, Cat Data, DataMining)              (Intro)   \n",
       "24               (Regression, DOE, DataMining)    (Cat Data, Intro)   \n",
       "25           (SW, Intro, Cat Data, DataMining)         (Regression)   \n",
       "26       (Survey, Regression, Cat Data, Intro)                (DOE)   \n",
       "27         (Survey, Regression, DOE, Cat Data)              (Intro)   \n",
       "28              (Survey, DOE, Forecast, Intro)           (Cat Data)   \n",
       "29            (Forecast, DOE, Cat Data, Intro)             (Survey)   \n",
       "30               (Survey, SW, Forecast, Intro)           (Cat Data)   \n",
       "31             (Forecast, SW, Cat Data, Intro)             (Survey)   \n",
       "32            (Survey, SW, Cat Data, Forecast)              (Intro)   \n",
       "33                      (Survey, SW, Forecast)    (Cat Data, Intro)   \n",
       "34             (Survey, Regression, SW, Intro)                (DOE)   \n",
       "35               (Survey, Regression, SW, DOE)              (Intro)   \n",
       "36                    (Survey, Regression, SW)         (DOE, Intro)   \n",
       "37             (Regression, SW, Cat Data, DOE)              (Intro)   \n",
       "\n",
       "    confidence       lift  \n",
       "0     0.818182   2.073864  \n",
       "1     1.000000   2.534722  \n",
       "2     0.800000   3.842105  \n",
       "3     1.000000   2.534722  \n",
       "4     1.000000   2.534722  \n",
       "5     1.000000   2.534722  \n",
       "6     1.000000   2.534722  \n",
       "7     1.000000   2.534722  \n",
       "8     1.000000   4.802632  \n",
       "9     1.000000   5.615385  \n",
       "10    1.000000   4.802632  \n",
       "11    1.000000   4.802632  \n",
       "12    1.000000   4.802632  \n",
       "13    1.000000   4.802632  \n",
       "14    1.000000   5.793651  \n",
       "15    1.000000   5.367647  \n",
       "16    1.000000   2.534722  \n",
       "17    1.000000   4.802632  \n",
       "18    1.000000   7.156863  \n",
       "19    1.000000   2.534722  \n",
       "20    1.000000   5.615385  \n",
       "21    1.000000  18.250000  \n",
       "22    1.000000   4.802632  \n",
       "23    1.000000   2.534722  \n",
       "24    1.000000  14.038462  \n",
       "25    1.000000   4.802632  \n",
       "26    1.000000   5.793651  \n",
       "27    1.000000   2.534722  \n",
       "28    1.000000   4.802632  \n",
       "29    1.000000   5.367647  \n",
       "30    1.000000   4.802632  \n",
       "31    1.000000   5.367647  \n",
       "32    1.000000   2.534722  \n",
       "33    1.000000  14.038462  \n",
       "34    1.000000   5.793651  \n",
       "35    1.000000   2.534722  \n",
       "36    1.000000  21.470588  \n",
       "37    1.000000   2.534722  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "\n",
    "frequent_itemsets = apriori(data,min_support=0.005,use_colnames=True) \n",
    "\n",
    "rules = association_rules(df=frequent_itemsets,metric=\"confidence\",min_threshold=0.8)\n",
    "\n",
    "rules[[\"antecedents\",\"consequents\",\"confidence\",\"lift\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason why the confidence might be 1 for every rule is that every time we see the antecedent, we see the consequent, and vice versa. In short, every course that is related to another course appears when the other course also appears, making the confidence essentially equal to 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "### The file Cosmetics.csv contains the data on the cosmetics purchases. Using Python, apply association rules to these data (use min_support=0.1 and min_threshold=0.8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trans.</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Blush</th>\n",
       "      <th>Nail Polish</th>\n",
       "      <th>Brushes</th>\n",
       "      <th>Concealer</th>\n",
       "      <th>Eyebrow Pencils</th>\n",
       "      <th>Bronzer</th>\n",
       "      <th>Lip liner</th>\n",
       "      <th>Mascara</th>\n",
       "      <th>Eye shadow</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Lip Gloss</th>\n",
       "      <th>Lipstick</th>\n",
       "      <th>Eyeliner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trans.   Bag  Blush  Nail Polish  Brushes  Concealer  Eyebrow Pencils  \\\n",
       "0        1    0      1            1        1          1                0   \n",
       "1        2    0      0            1        0          1                0   \n",
       "2        3    0      1            0        0          1                1   \n",
       "3        4    0      0            1        1          1                0   \n",
       "4        5    0      1            0        0          1                0   \n",
       "\n",
       "   Bronzer  Lip liner  Mascara  Eye shadow  Foundation  Lip Gloss  Lipstick  \\\n",
       "0        1          1        1           0           0          0         0   \n",
       "1        1          1        0           0           1          1         0   \n",
       "2        1          1        1           1           1          1         1   \n",
       "3        1          0        0           0           1          0         0   \n",
       "4        1          1        1           1           0          1         1   \n",
       "\n",
       "   Eyeliner  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cos_data = pd.read_csv(\"Cosmetics.csv\")\n",
    "cos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Brushes)</td>\n",
       "      <td>(Nail Polish)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>2.359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>2.359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Lip liner, Blush)</td>\n",
       "      <td>(Concealer)</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>1.970515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.601040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Mascara, Blush)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>2.410704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Eye shadow, Nail Polish)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.544529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Mascara, Nail Polish)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.888060</td>\n",
       "      <td>2.330865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Lip liner, Bronzer)</td>\n",
       "      <td>(Concealer)</td>\n",
       "      <td>0.804687</td>\n",
       "      <td>1.820560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Eyeliner, Bronzer)</td>\n",
       "      <td>(Concealer)</td>\n",
       "      <td>0.815068</td>\n",
       "      <td>1.844046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Eyeliner, Lip liner)</td>\n",
       "      <td>(Concealer)</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>2.088409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Concealer, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>2.494530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Concealer, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>2.303021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Eye shadow, Bronzer)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>2.463397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Mascara, Bronzer)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>2.375615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Mascara, Foundation)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>2.269248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Lip Gloss, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>2.291150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Eye shadow, Lipstick)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>2.388552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Mascara, Lipstick)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.386065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Eye shadow, Eyeliner)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>2.324007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(Mascara, Eyeliner)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>2.264717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Concealer, Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>2.688172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Concealer, Mascara, Blush)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.384244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(Concealer, Eye shadow, Eyeliner)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>2.456367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Concealer, Mascara, Eyeliner)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>2.232930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(Lip Gloss, Mascara, Foundation)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>2.241066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          antecedents    consequents  confidence      lift\n",
       "0                           (Brushes)  (Nail Polish)    1.000000  3.571429\n",
       "1                        (Eye shadow)      (Mascara)    0.842520  2.359999\n",
       "2                           (Mascara)   (Eye shadow)    0.899160  2.359999\n",
       "3                  (Lip liner, Blush)    (Concealer)    0.870968  1.970515\n",
       "4                 (Eye shadow, Blush)      (Mascara)    0.928571  2.601040\n",
       "5                    (Mascara, Blush)   (Eye shadow)    0.918478  2.410704\n",
       "6           (Eye shadow, Nail Polish)      (Mascara)    0.908397  2.544529\n",
       "7              (Mascara, Nail Polish)   (Eye shadow)    0.888060  2.330865\n",
       "8                (Lip liner, Bronzer)    (Concealer)    0.804687  1.820560\n",
       "9                 (Eyeliner, Bronzer)    (Concealer)    0.815068  1.844046\n",
       "10              (Eyeliner, Lip liner)    (Concealer)    0.923077  2.088409\n",
       "11            (Concealer, Eye shadow)      (Mascara)    0.890547  2.494530\n",
       "12               (Concealer, Mascara)   (Eye shadow)    0.877451  2.303021\n",
       "13              (Eye shadow, Bronzer)      (Mascara)    0.879433  2.463397\n",
       "14                 (Mascara, Bronzer)   (Eye shadow)    0.905109  2.375615\n",
       "15              (Mascara, Foundation)   (Eye shadow)    0.864583  2.269248\n",
       "16               (Lip Gloss, Mascara)   (Eye shadow)    0.872928  2.291150\n",
       "17             (Eye shadow, Lipstick)      (Mascara)    0.852713  2.388552\n",
       "18                (Mascara, Lipstick)   (Eye shadow)    0.909091  2.386065\n",
       "19             (Eye shadow, Eyeliner)      (Mascara)    0.829670  2.324007\n",
       "20                (Mascara, Eyeliner)   (Eye shadow)    0.862857  2.264717\n",
       "21     (Concealer, Eye shadow, Blush)      (Mascara)    0.959677  2.688172\n",
       "22        (Concealer, Mascara, Blush)   (Eye shadow)    0.908397  2.384244\n",
       "23  (Concealer, Eye shadow, Eyeliner)      (Mascara)    0.876923  2.456367\n",
       "24     (Concealer, Mascara, Eyeliner)   (Eye shadow)    0.850746  2.232930\n",
       "25   (Lip Gloss, Mascara, Foundation)   (Eye shadow)    0.853846  2.241066"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "\n",
    "cos_data = cos_data.drop(\"Trans. \",axis=1)\n",
    "frequent_itemsets = apriori(cos_data,min_support=0.1,use_colnames=True) \n",
    "\n",
    "rules = association_rules(df=frequent_itemsets,metric=\"confidence\",min_threshold=0.8)\n",
    "\n",
    "rules[[\"antecedents\",\"consequents\",\"confidence\",\"lift\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Interpret the first three rules in the output in words.\n",
    "Interpreting the results of the association rules in the first three rules, we see that when brushes are purchased, there is a 100% confidence that nail polish will also be purchased with a lift ratio of 3.57. We see with rules 2 and 3 that there is some apparent redundancy as in rule 2 eye shadow is the antecedent and mascara is the consequent and in rule 3 we see the opposite, mascara is the antecedent and eye shadow is the consequent. Now, there is clearly a relationship between the two with confidence being 84.25% for rule 2 and the confidence being 89.92 for rule three with the same lift ratios in both cases. \n",
    "\n",
    "## b. Reviewing the first couple of dozen rules, comment on their redundancy and how you would assess their utility.\n",
    "We've already commented on rules 2 and 3. Looking through our list of rules, we see that nearly every rule contains the relationship between eye shadow and mascara, combined with some other combination of products. This does not necessarily mean our rules are useless; however, we would need to assess our different rules and do some consolidating of rules before we could move forward with new data. Another notable mention is rules 9,10, and 11. These rules also contain the elements concealer, eyeliner, bronzer, and concealment which might also have the ability to be consolidated. \n",
    "\n",
    "## Course Ratings:\n",
    "## Scenario: \n",
    "The Institute for Statistics Education at Statistics.com asks students to rate\n",
    "a variety of aspects of a course as soon as the student completes it. The Institute is\n",
    "contemplating instituting a recommendation system that would provide students with\n",
    "recommendations for additional courses as soon as they submit their rating for a\n",
    "completed course\n",
    "\n",
    "## Question 3:\n",
    "### Just reviewing the data visually, without doing much calculation, which user(s) would you consider most similar to E.N.?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQL</th>\n",
       "      <th>Spatial</th>\n",
       "      <th>PA1</th>\n",
       "      <th>DM in R</th>\n",
       "      <th>Python</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>R Prog</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Regression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LN</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JH</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SQL  Spatial  PA1  DM in R  Python  Forecast  R Prog  Hadoop  \\\n",
       "Unnamed: 0                                                                 \n",
       "LN          4.0      NaN  NaN      NaN     3.0       2.0     4.0     NaN   \n",
       "MH          3.0      4.0  NaN      NaN     4.0       NaN     NaN     NaN   \n",
       "JH          2.0      2.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "EN          4.0      NaN  NaN      4.0     NaN       NaN     4.0     NaN   \n",
       "DU          4.0      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "FL          NaN      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "GL          NaN      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "AH          NaN      3.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "SA          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "RW          NaN      NaN  2.0      NaN     NaN       NaN     NaN     4.0   \n",
       "BA          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "MG          NaN      NaN  4.0      NaN     NaN       4.0     NaN     NaN   \n",
       "AF          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "KG          NaN      NaN  3.0      NaN     NaN       NaN     NaN     NaN   \n",
       "DS          4.0      NaN  NaN      2.0     NaN       NaN     4.0     NaN   \n",
       "\n",
       "            Regression  \n",
       "Unnamed: 0              \n",
       "LN                 2.0  \n",
       "MH                 NaN  \n",
       "JH                 NaN  \n",
       "EN                 3.0  \n",
       "DU                 NaN  \n",
       "FL                 NaN  \n",
       "GL                 NaN  \n",
       "AH                 NaN  \n",
       "SA                 NaN  \n",
       "RW                 NaN  \n",
       "BA                 NaN  \n",
       "MG                 NaN  \n",
       "AF                 NaN  \n",
       "KG                 NaN  \n",
       "DS                 NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "course_data = pd.read_csv(\"courserating.csv\")\n",
    "course_data.set_index(\"Unnamed: 0\",inplace=True)\n",
    "course_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above data, from simply looking at the data, we see two entries that are similar to entry EN, LN and DS. LN and DS both have three class ratings in common with EN, albeit with different values for the ratings. We see DS and EN shared ratings with SQL (4.0), R Prog (4.0), and DM in R (here there is a difference of 2 in the rating values). Between LN and EN we see three classes with shared ratings as well: SQL (4.0), R Prog (4.0), and Regression (here there is a difference of 1). Since the total difference between LN and EN is less than the total distance between DS and EN, we can say that LN and EN are more similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>course</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LN</td>\n",
       "      <td>SQL</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LN</td>\n",
       "      <td>Spatial</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LN</td>\n",
       "      <td>PA1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LN</td>\n",
       "      <td>DM in R</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LN</td>\n",
       "      <td>Python</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer   course  value\n",
       "0       LN      SQL    4.0\n",
       "1       LN  Spatial    NaN\n",
       "2       LN      PA1    NaN\n",
       "3       LN  DM in R    NaN\n",
       "4       LN   Python    3.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = []\n",
    "for customer,row in course_data.iterrows():\n",
    "    for course, value in row.iteritems():\n",
    "        if value==0: continue\n",
    "        ratings.append([customer,course,value])\n",
    "ratings = pd.DataFrame(ratings,columns=[\"customer\",\"course\",\"value\"])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KNNBasic' from 'surprise' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNNBasic\n\u001b[0;32m      3\u001b[0m sim_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_based\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m      4\u001b[0m algo \u001b[38;5;241m=\u001b[39m KNNBasic(sim_options\u001b[38;5;241m=\u001b[39msim_options)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'KNNBasic' from 'surprise' (unknown location)"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "sim_options = {\"name\":\"cosine\",\"user_based\":False}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m course_data\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m----> 3\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43m[\u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcourse\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcourse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m]\u001b[49m)\n",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m course_data\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m----> 3\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend([\u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(user,course)\u001b[38;5;241m.\u001b[39mest \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m course_data])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for user in course_data.index:\n",
    "    predictions.append([algo.predict(user,course).est for course in course_data])\n",
    "predictions = pd.DataFrame(predictions,columns=course_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "### Use Python to compute the cosine similarity between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LN</th>\n",
       "      <th>MH</th>\n",
       "      <th>JH</th>\n",
       "      <th>EN</th>\n",
       "      <th>DU</th>\n",
       "      <th>FL</th>\n",
       "      <th>GL</th>\n",
       "      <th>AH</th>\n",
       "      <th>SA</th>\n",
       "      <th>RW</th>\n",
       "      <th>BA</th>\n",
       "      <th>MG</th>\n",
       "      <th>AF</th>\n",
       "      <th>KG</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LN</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JH</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>0.9891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0      LN        MH        JH       EN        DU   FL   GL   AH   SA  \\\n",
       "Unnamed: 0                                                                      \n",
       "LN          1.0000  0.960000  1.000000  0.98910  1.000000  NaN  NaN  NaN  NaN   \n",
       "MH          0.9600  1.000000  0.989949  1.00000  0.989949  1.0  1.0  1.0  NaN   \n",
       "JH          1.0000  0.989949  1.000000  1.00000  1.000000  1.0  1.0  1.0  NaN   \n",
       "EN          0.9891  1.000000  1.000000  1.00000  1.000000  NaN  NaN  NaN  NaN   \n",
       "DU          1.0000  0.989949  1.000000  1.00000  1.000000  1.0  1.0  1.0  NaN   \n",
       "FL             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "GL             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "AH             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "SA             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "RW             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "BA             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "MG          1.0000       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "AF             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "KG             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "DS          1.0000  1.000000  1.000000  0.96225  1.000000  NaN  NaN  NaN  NaN   \n",
       "\n",
       "Unnamed: 0   RW   BA   MG   AF   KG       DS  \n",
       "Unnamed: 0                                    \n",
       "LN          NaN  NaN  1.0  NaN  NaN  1.00000  \n",
       "MH          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "JH          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "EN          NaN  NaN  NaN  NaN  NaN  0.96225  \n",
       "DU          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "FL          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "GL          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "AH          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "SA          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "RW          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "BA          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "MG          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "AF          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "KG          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "DS          NaN  NaN  NaN  NaN  NaN  1.00000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def cosine_similarity_NA(data):\n",
    "     m = data.shape[0]\n",
    "     # Initialize the similarity matrix to np.nan\n",
    "     result = np.full((m, m), np.nan)\n",
    "     # Iterate over all pairs of columns\n",
    "     for i in range(m):\n",
    "         # maski is true if a value exists in column i\n",
    "         maski = ~np.isnan(data.iloc[i])\n",
    "         for j in range(i, m):\n",
    "             # maskij is true if a value exists in both column i and j\n",
    "             maskij = maski & ~np.isnan(data.iloc[j])\n",
    "             if np.any(maskij):\n",
    "                 # if there are values in both columns, calculate the cosine similarity\n",
    "                 # for these\n",
    "                 result[i, j] = 1 - cosine(data.iloc[i][maskij], data.iloc[j][maskij])\n",
    "                 result[j, i] = result[i, j]\n",
    "     return pd.DataFrame(result, columns=data.index, index=data.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cosine_similarity_NA(course_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a matrix of the different cosine values from the ratings dataframe. If we wanted to observe the cosine for LN and EN, we could look at the cell that matches the two of them and return the value. The value is 0.9891. Looking across the row for EN, we observe that DS has a cosine relationship with EN of 0.9623. \n",
    "\n",
    "## Question 5: \n",
    "### Based on the cosine similarities of the nearest students to E.N., which course should be recommended to E.N.?\n",
    "\n",
    "Looking at the cosine table and back at the course dataframe, we do see that only DS and Ln are closest to EN so we will see which classes they have taken that EN has not. We see that DS only took a total of three classes, so this does not help us recommend a new class to EN. However, looking at LN, we see LN has taken five classes, two of which EN has not taken- Python and Forecast. Based on this information and the fact that LN gave Python a higher rating, we should recommend Python first and then Forecast. \n",
    "\n",
    "## Question 6:\n",
    "### With large datasets, it is computationally difficult to compute user-based recommendations in real time, and an item-based approach is used instead. Returning to the rating data (not the binary matrix), letâ€™s now take that approach.\n",
    "### 1. If the goal is still to find a recommendation for E.N., for which course pairs is it possible and useful to calculate correlations?\n",
    "\n",
    "It seems there might be some sort of correlation between SQL and Spatial and potentially Python and SQL as there are some similar ratings between these courses. \n",
    "\n",
    "### 2. Just looking at the data, and without yet calculating course pair correlations, which course would you recommend to E.N., relying on itembased filtering? Calculate two course pair correlations involving your guess and report the results.\n",
    "\n",
    "Without calculating course pair correlations, I would recommend Spatial and Python to user E.N. \n",
    "\n",
    "Below are the course pair correlations:\n",
    "- Spatial and SQL: 0.8182 \n",
    "- Python and SQL: -0.9999 or -1, a nearly perfect negative correlation\n",
    "\n",
    "## Question 7: \n",
    "### Apply item-based collaborative filtering to the dataset (using the Surprise package in Python) and based on the results, recommend a course to E.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"EN\"\n",
    "if user_id in ratings['customer'].unique():\n",
    "    user_ratings = ratings[ratings['customer'] == user_id]\n",
    "    predictions = [(course, algo.predict(user_id, course).est) for course in user_ratings['course']]\n",
    "\n",
    "    print(f'Predictions for user {user_id}:')\n",
    "    for course, prediction in predictions:\n",
    "        print(f'Course: {course}, Prediction: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, we see the courses EN has already taken along with the other likelihoods of the other courses. Based on the prediction from the code, Python has the highest prediction likelihood of the courses EN has not yet taken at 3.5027. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
